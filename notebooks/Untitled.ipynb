{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from six import iteritems\n",
    "import shelve\n",
    "from scipy.ndimage.measurements import label\n",
    "import h5py\n",
    "import json\n",
    "import sys \n",
    "import operator \n",
    "from scipy import ndimage\n",
    "\n",
    "from pdb import set_trace as st\n",
    "import copy\n",
    "import os\n",
    "#from IPython.display import Image, display\n",
    "from ipywidgets import interact, fixed\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from os.path import expanduser\n",
    "import time\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torch.nn.parallel import data_parallel\n",
    "from torchvision import transforms\n",
    "\n",
    "from visualize import simple_visualizer\n",
    "\n",
    "import random\n",
    "import six\n",
    "\n",
    "import importlib\n",
    "\n",
    "import artificery\n",
    "import metroem\n",
    "importlib.reload(metroem)\n",
    "import torchfields\n",
    "\n",
    "from metroem import loss\n",
    "from metroem import masks\n",
    "from metroem import alignment\n",
    "from metroem import aligner\n",
    "from metroem import train\n",
    "from metroem import helpers\n",
    "from metroem import dataset\n",
    "\n",
    "importlib.reload(helpers)\n",
    "importlib.reload(aligner)\n",
    "importlib.reload(alignment)\n",
    "importlib.reload(masks)\n",
    "importlib.reload(loss)\n",
    "importlib.reload(train)\n",
    "importlib.reload(dataset)\n",
    "\n",
    "from metroem.alignment import align_sample\n",
    "from metroem.loss import similarity_score, smoothness_penalty, get_dataset_loss, get_mse_and_smoothness_masks, smoothness_score\n",
    "from metroem.helpers import reverse_dim, downsample\n",
    "\n",
    "def visualize_residuals(res, figsize=(10,10), x_coords=None, y_coords=None, vec_grid=50):\n",
    "    res = prepare_for_show(res)\n",
    "    if res.shape[0] == 2:\n",
    "        res = np.transpose(res, (1, 2, 0))\n",
    "\n",
    "    assert res.shape[0] == res.shape[1]\n",
    "    plt.figure(figsize=figsize)\n",
    "    n = res.shape[0]\n",
    "    y, x = np.mgrid[0:n, 0:n]\n",
    "    \n",
    "    if x_coords is None:\n",
    "        x_coords = [0, res.shape[0]]\n",
    "    if y_coords is None:\n",
    "        y_coords = [0, res.shape[1]]\n",
    "    \n",
    "    ex = (1) * res[:, :, 0]\n",
    "    ey = res[:, :, 1]\n",
    "    r = np.arctan2(ex, ey)\n",
    "    \n",
    "    interval = (x_coords[1] - x_coords[0]) // vec_grid\n",
    "    \n",
    "    plt.quiver(  x[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval],  \n",
    "                 y[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval],\n",
    "                ex[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval], \n",
    "                ey[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval], \n",
    "                 r[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval], alpha=0.6)\n",
    "    plt.quiver(x[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval],  \n",
    "                 y[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval],\n",
    "                ex[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval], \n",
    "                ey[x_coords[0]:x_coords[1]:interval, y_coords[0]:y_coords[1]:interval], edgecolor='k', facecolor='None', linewidth=.5)\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "def visualize_histogram(data, figsize=(10,10), x_coords=None, y_coords=None):\n",
    "    pass\n",
    "    \n",
    "def get_np(pt):\n",
    "    return pt.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "def prepare_for_show(img):\n",
    "    if isinstance(img, torch.Tensor):\n",
    "         img = get_np(img)\n",
    "    img = img.squeeze()\n",
    "    return img\n",
    "\n",
    "\n",
    "rand_cmap = matplotlib.colors.ListedColormap(np.random.rand(256*32,3))\n",
    "\n",
    "def display_image(img, x_coords=None, y_coords=None, normalize=False, figsize=(10, 10), mask=False, segmentation=False):\n",
    "    if normalize and mask:\n",
    "        raise Exception(\"Masks can't be normalized\")\n",
    "    img = prepare_for_show(img)\n",
    "\n",
    "    if len(img.shape) == 3 and img.shape[-1] == 2:\n",
    "        visualize_residuals(img, x_coords=x_coords, y_coords=y_coords)\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    if x_coords is None:\n",
    "        x_coords = [0, img.shape[0]]\n",
    "    if y_coords is None:\n",
    "        y_coords = [0, img.shape[1]]\n",
    "    \n",
    "    if mask:\n",
    "        plt.imshow(img[x_coords[0]:x_coords[1], y_coords[0]:y_coords[1]], cmap='gray')\n",
    "    elif segmentation:\n",
    "        cmap='gray'\n",
    "        cmap = rand_cmap\n",
    "        \n",
    "        plt.imshow(img[x_coords[0]:x_coords[1], y_coords[0]:y_coords[1]].astype(np.int32), cmap=cmap)\n",
    "    elif not normalize:\n",
    "        plt.imshow(img[x_coords[0]:x_coords[1], y_coords[0]:y_coords[1]], cmap='gray', vmin=-1.5, vmax=1.5)\n",
    "    else:\n",
    "        plt.imshow(img[x_coords[0]:x_coords[1], y_coords[0]:y_coords[1]], cmap='gray')\n",
    "\n",
    "        \n",
    "def precompute_state(self, img_id, sup, val, state_file):\n",
    "    self.compute_state(img_id, sup, val)\n",
    "    try:\n",
    "        \n",
    "        state_h5 = h5py.File(state_file, 'w')\n",
    "        img_shape = self.src.shape\n",
    "        dset_shape = [0, 100, img_shape[3], img_shape[4]]\n",
    "        if \"main\" not in state_h5:\n",
    "            src_h5 = state_h5.create_dataset(\"main/src\", dset_shape)\n",
    "            tgt_h5 = state_h5.create_dataset(\"main/tgt\", dset_shape)\n",
    "            pred_tgt_h5 = state_h5.create_dataset(\"main/pred_tgt_h5\", dset_shape)\n",
    "        else:\n",
    "            src_h5 = state_h5[\"main/src\"]\n",
    "            tgt_h5 = state_h5[\"main/tgt\"]\n",
    "            pred_tgt_h5 = state_h5[\"main/pred_tgt\"]\n",
    "        src_h5[:, img_id:img_id+1, :, :] = 0#self.src \n",
    "        tgt_h5[:, img_id:img_id+1, :, :] = 0#self.tgt\n",
    "        pred_tgt_h5[:, img_id:img_id+1, :, :] = 0#self.pred_tgt_h5\n",
    "        state_h5.close()\n",
    "    except Exception as e:\n",
    "        state_h5.close()\n",
    "        raise e\n",
    "\n",
    "def filter_folds(viz_mse_mask_var, input_mip=6):\n",
    "    downsampler = nn.AvgPool2d(2) \n",
    "    for i in range(input_mip, 8):\n",
    "        viz_mse_mask_var = downsampler(viz_mse_mask_var)\n",
    "        \n",
    "    viz_mse_mask_var = (viz_mse_mask_var < 0.3).type(torch.cuda.DoubleTensor)\n",
    "                           \n",
    "    viz_mse_mask_var = viz_mse_mask_var.type(torch.cuda.ByteTensor)\n",
    "    mse_mask_np = get_np(viz_mse_mask_var.squeeze())\n",
    "    filtered_mse_mask_np = filter_connected_component(mse_mask_np, 100) == 0\n",
    "    return filtered_mse_mask_np\n",
    "\n",
    "        \n",
    "def segment_folds(fold_mask_np, memory_limit=None):\n",
    "    initial_segments = get_initial_segments(fold_mask_np, memory_limit)\n",
    "    segments  = cleanup_segment_stripes(initial_segments, n=16)\n",
    "    return segments\n",
    "\n",
    "def cleanup_segment_stripes(segments, n):\n",
    "    seg_t = np.copy(segments.T)\n",
    "    seg_start = np.zeros_like(seg_t[0])\n",
    "    last_seg = np.zeros_like(seg_t[1])\n",
    "    last_cleanup = 0\n",
    "    \n",
    "    for i in range(1, seg_t.shape[0]): \n",
    "        is_fold = seg_t[i] == 0\n",
    "        was_fold = seg_t[i - 1] == 0\n",
    "        last_seg_fold = last_seg == 0\n",
    "        \n",
    "        new_seg = (seg_t[i] != seg_t[i - 1])\n",
    "        seg_width = i - seg_start\n",
    "        \n",
    "        bad_seg = new_seg * (seg_width < n) * (was_fold == False) * (is_fold == False)\n",
    "        bad_seg_names = np.unique(seg_t[i - 1][bad_seg])\n",
    "        \n",
    "        if len(bad_seg_names) > 0:\n",
    "            print (i, last_cleanup, bad_seg_names)\n",
    "            cleanup_seg_id = i - 2\n",
    "            ref_seg_id = i - 1\n",
    "\n",
    "            ids_to_clean = None\n",
    "            change_to_these = np.maximum(last_seg, new_seg)\n",
    "            while (cleanup_seg_id >= 0):\n",
    "                ids_to_clean = (seg_t[cleanup_seg_id] == seg_t[ref_seg_id]) * bad_seg * (last_seg_fold == False)\n",
    "                if np.any(ids_to_clean) == False:\n",
    "                    break\n",
    "                seg_t[cleanup_seg_id][ids_to_clean] = change_to_these[ids_to_clean]\n",
    "                cleanup_seg_id -= 1\n",
    "            seg_t[ref_seg_id][bad_seg * (last_seg_fold == False)] = change_to_these[bad_seg * (last_seg_fold == False)]\n",
    "            last_cleanup = i\n",
    "                                  \n",
    "        last_seg[new_seg] = seg_t[i - 1][new_seg]\n",
    "        seg_start[new_seg] = i\n",
    "    return seg_t.T\n",
    "\n",
    "def get_initial_segments(fold_mask_np, memory_limit, smallest_seg):\n",
    "    folds = fold_mask_np == False\n",
    "    segments = np.zeros_like(folds, dtype=np.int32)\n",
    "    last_fold = np.zeros_like(folds[0], dtype=np.int32)\n",
    "    seg_start = np.zeros_like(folds[0], dtype=np.int32)\n",
    "    \n",
    "    segments[0] = 1\n",
    "    segments[0][folds[0]] = 0\n",
    "    max_in_line = np.copy(segments[0])\n",
    "    \n",
    "    \n",
    "    for i in range(1, folds.shape[0]):\n",
    "        \n",
    "        \n",
    "        is_fold = folds[i]\n",
    "        was_fold = folds[i - 1]\n",
    "        curr_seg = segments[i]\n",
    "        last_seg = segments[i - 1]\n",
    "        \n",
    "        continue_ids = (is_fold == False) * (was_fold == False)\n",
    "        short_stretch = (i - seg_start) < smallest_seg\n",
    "        \n",
    "        new_seg_ids = (is_fold == False) * (was_fold == True) * (short_stretch == False)\n",
    "        jump_seg_ids = (is_fold == False) * (was_fold == True) * (short_stretch == True)\n",
    "        \n",
    "        curr_seg[continue_ids] = last_seg[continue_ids]\n",
    "        curr_seg[new_seg_ids] = (max_in_line + 1)[new_seg_ids]\n",
    "        \n",
    "        fresh_start_ids = max_in_line == 0\n",
    "        curr_seg[jump_seg_ids * (fresh_start_ids == False)] = max_in_line[jump_seg_ids * (fresh_start_ids == False)]\n",
    "        curr_seg[jump_seg_ids * (fresh_start_ids == True)] = (max_in_line + 1)[jump_seg_ids * (fresh_start_ids == True)]\n",
    "        \n",
    "        seg_start[new_seg_ids] = i\n",
    "        \n",
    "        curr_seg[is_fold == True] = 0\n",
    "        max_in_line = np.maximum(max_in_line, curr_seg)\n",
    "        \n",
    "        '''if memory_limit is not None:\n",
    "            forgotten_folds = (i - last_fold) > memory_limit\n",
    "            max_in_line[forgotten_folds] = np.maximum(1, max_in_line[forgotten_folds] - 1)'''\n",
    "        last_fold[is_fold] = i\n",
    "        \n",
    "    return segments \n",
    "\n",
    "def expand_mask(mask_np, n=33):\n",
    "    mask_var = torch.FloatTensor(mask_np.astype(np.float)).unsqueeze(0).unsqueeze(0)\n",
    "    kernel = torch.ones([1, 1, n, n])\n",
    "    expanded_mask = torch.nn.functional.conv2d(mask_var, kernel, padding=n//2) \n",
    "    expanded_mask_np = get_np(expanded_mask[0, 0]) > 0\n",
    "    return expanded_mask_np\n",
    "\n",
    "class PyramidVisualizer(object):\n",
    "    def __init__(self, pyramid, def_sup=False):\n",
    "        self.reverse = True\n",
    "        self.fold_size = None\n",
    "        self.src = None\n",
    "        self.prev_id = -1\n",
    "        self.prev_is_val = False\n",
    "        self.prev_is_sup = False\n",
    "        self.val_dataset = None\n",
    "        self.train_dataset = None\n",
    "        self.def_sup = True\n",
    "        self.def_norm_img = False\n",
    "        self.viz_mip = 0\n",
    "        self.run_mip = 0\n",
    "        self.sup = False\n",
    "        self.prerun_augment = []\n",
    "        \n",
    "        self.pyramid = pyramid\n",
    "        self.run_mip = 0\n",
    "        self.viz_mip = 0\n",
    "        \n",
    "        \n",
    "        self.dataset_mip, self.sup_train_dataset = get_datasets()\n",
    "        #self.upsampler = nn.UpsamplingBilinear2d(scale_factor=2)   \n",
    "        self.mse_keys_to_apply = {\n",
    "        'src': [\n",
    "            {'name': 'src_defects',\n",
    "             'binarization': {'strat': 'eq', 'value': 0},\n",
    "             \"not_coarsen_ranges\": [ (0,25)] },\n",
    "            {'name': 'src',\n",
    "             \"not_coarsen_ranges\": [(1, 0)],\n",
    "             'binarization': {'strat': 'neq', 'value': 0}\n",
    "             }\n",
    "            ],\n",
    "        'tgt':[\n",
    "            {'name': 'tgt_defects',\n",
    "             'binarization': {'strat': 'eq', 'value': 0},\n",
    "             \"coarsen_ranges\": [(0, 0)]},\n",
    "            {'name': 'tgt',\n",
    "             \"not_coarsen_ranges\": [(10, 0)],\n",
    "             'binarization': {'strat': 'neq', 'value': 0}\n",
    "             }\n",
    "        ]\n",
    "    }\n",
    "        self.sm_keys_to_apply = {                                                                                                 \n",
    "           \"src\": [                                                                                                          \n",
    "               {\"name\": \"src_defects\",                                                                                      \n",
    "                \"binarization\": {\"strat\": \"eq\", \"value\": 0},                                                               \n",
    "                \"not_coarsen_ranges\": [[1, 0.2], [4, 5.0]],                                                             \n",
    "                \"mask_value\": 1.0e-5},                                                                                       \n",
    "             {\"name\": \"src\",                                                                                             \n",
    "                \"fm\": 0,                                                                                                  \n",
    "                \"binarization\": {\"strat\": \"neq\", \"value\": 0}}                                                            \n",
    "           ],                                                                                                              \n",
    "           \"tgt\":[                                                                                                        \n",
    "               {\"name\": \"tgt_defects\",                                                                                   \n",
    "                \"binarization\": {\"strat\": \"eq\", \"value\": 0},                                                                 \n",
    "                #\"not_coarsen_ranges\": [[1, 0.2], [2, 0.4], [3, 0.6], [4, 0.8]],                                                              \n",
    "                \"mask_value\": 0.0e-5}                                                                                         \n",
    "           ]                                                                                                              \n",
    "       }\n",
    "        \n",
    "    \n",
    "        \n",
    "    def set_model(self, model):\n",
    "        self.pyramid = model\n",
    "        self.prev_id = -1\n",
    "    \n",
    "    def update_state(self, img_id, sup, val, state_file):\n",
    "        if state_file is None:\n",
    "            \n",
    "            self.compute_state(img_id, sup, val)\n",
    "        else:\n",
    "            self.load_state(img_id, sup, val, state_file)\n",
    "            \n",
    "    def compute_state(self, img_id, sup, val):\n",
    "        self.dataset = self.sup_train_dataset\n",
    "                \n",
    "        if self.prev_id == -1:\n",
    "            self.clean_up()\n",
    "            \n",
    "        #make it refresh when sup is changed\n",
    "        if self.prev_id == -1 or self.prev_is_sup != sup:\n",
    "            self.prev_is_sup = sup\n",
    "            self.prev_id = -1\n",
    "            \n",
    "\n",
    "        if img_id != self.prev_id or self.prev_is_val != val:\n",
    "            self.prev_id = img_id\n",
    "            self.prev_is_val = val\n",
    "            #clean_sample = self.dataset[img_id][:, 2:-30, 2:-30].unsqueeze(0)\n",
    "            \n",
    "            raw_sample = copy.deepcopy(self.dataset[img_id])\n",
    "           \n",
    "            for aug in self.prerun_augment:\n",
    "                if aug['type'] == 'contrast_half_src':\n",
    "                    src = raw_sample[0, 0]\n",
    "                    src[src.shape[0]//2:, :] *= aug['mult']\n",
    "                elif aug['type'] == 'brightness_half_src':\n",
    "                    src = raw_sample[0, 0]\n",
    "                    src[src.shape[0]//2:, :] += aug['bump']\n",
    "                else:\n",
    "                    raise Exception(\"Unknown prerun transofm\")\n",
    "                    \n",
    "            for k, v in six.iteritems(raw_sample):\n",
    "                #print (v.shape)\n",
    "                # why are we doing this\n",
    "                raw_sample[k] = v.unsqueeze(0)  \n",
    "                \n",
    "            run_sample = copy.deepcopy(raw_sample)\n",
    "            self.run_sample = run_sample\n",
    "            for k, v in six.iteritems(run_sample):\n",
    "                #print (v.shape)\n",
    "                # why are we doing this: to have the same orientation as ng\n",
    "                #run_sample[k] = v.permute(0, 2, 1)\n",
    "                pass\n",
    "            \n",
    "            model_run_params = {\"level_in\": self.run_mip}\n",
    "            \n",
    "            run_result = align_sample(self.pyramid, run_sample)\n",
    "            for k, v in six.iteritems(run_result):\n",
    "                if hasattr(v, 'detach'):\n",
    "                    run_result[k] = v.detach()\n",
    "                \n",
    "            run_src_var = run_result['src'].unsqueeze(0)                                                                   \n",
    "            run_tgt_var = run_result['tgt'].unsqueeze(0)                                                                                                                             \n",
    "            run_pred_res_var = run_result['pred_res']                                                                \n",
    "            del run_result\n",
    "            \n",
    "            '''run_result = self.pyramid.run_pair(run_sample.unsqueeze(0), self.run_mip, reverse=self.reverse)\n",
    "            run_src_var, run_tgt_var, run_true_res_var, run_pred_res_var, run_pred_tgt_var, run_masks_var = run_result\n",
    "            \n",
    "            del run_result, run_true_res_var, run_pred_tgt_var, run_masks_var'''\n",
    "            \n",
    "            #clean_smale = self.dataset[img_id][:, 2:-30, 2:-30].unsqueeze(0)\n",
    "            viz_sample = copy.deepcopy(raw_sample)\n",
    "                    \n",
    "            viz_src_var = viz_sample['src']\n",
    "            viz_tgt_var = viz_sample['tgt']\n",
    "            \n",
    "            if self.sup:\n",
    "                viz_true_res_var = viz_sample['res']\n",
    "\n",
    "            viz_src_var = viz_src_var\n",
    "            viz_tgt_var = viz_tgt_var\n",
    "            \n",
    "            \n",
    "            viz_pred_res_var = run_pred_res_var#.permute(0, 2, 1, 3).flip(3)\n",
    "            \n",
    "            viz_pred_res_var = viz_pred_res_var.squeeze()\n",
    "            viz_sample['pred_res'] = viz_pred_res_var\n",
    "            \n",
    "            if 'src_field' in viz_sample:\n",
    "                src_res_var = viz_sample['src_field'].field()\n",
    "            else:\n",
    "                src_res_var = torch.zeros_like(run_pred_res_var).field()\n",
    "                \n",
    "            viz_warped_src_var = src_res_var.from_pixels()(viz_src_var)\n",
    "            viz_pred_tgt_var = viz_pred_res_var.from_pixels()(viz_src_var)\n",
    "            \n",
    "            viz_sample['pred_tgt'] = viz_pred_tgt_var\n",
    "\n",
    "\n",
    "            viz_mse_mask_var, viz_smoothness_mask_var = get_mse_and_smoothness_masks(viz_sample, \n",
    "                                                                                     mse_keys_to_apply=self.mse_keys_to_apply,\n",
    "                                                                                    sm_keys_to_apply=self.sm_keys_to_apply)\n",
    "            \n",
    "            \n",
    "            self.viz_sample = viz_sample\n",
    "            # Todo: visualize different penalties\n",
    "            \n",
    "            viz_rigidity_penalty_var = loss.rigidity(viz_pred_res_var.unsqueeze(0))\n",
    "            viz_smoothness_penalty_var = viz_rigidity_penalty_var\n",
    "            \n",
    "            norm_tgt_var = torch.nn.InstanceNorm2d(1)(viz_tgt_var.unsqueeze(0))\n",
    "            norm_pred_tgt_var = torch.nn.InstanceNorm2d(1)(viz_pred_tgt_var.unsqueeze(0))\n",
    "            viz_masked_nrom_diff_var = viz_mse_mask_var * torch.abs(viz_tgt_var - viz_pred_tgt_var)\n",
    "            del norm_tgt_var, norm_pred_tgt_var\n",
    "            \n",
    "            viz_diff_var = (viz_tgt_var - viz_pred_tgt_var)**2\n",
    "            viz_masked_diff_var = viz_diff_var * viz_mse_mask_var\n",
    "            viz_inv_res = torch.zeros_like(viz_pred_res_var)\n",
    "            combined_identity_var = viz_inv_res\n",
    " \n",
    "            self.img_dict = {\n",
    "                'Source': {\"img\": get_np(viz_src_var), \"norm\": self.def_norm_img},\n",
    "                'Warped Source': {\"img\": get_np(viz_warped_src_var), \"norm\": self.def_norm_img},\n",
    "                'Target': {\"img\": get_np(viz_tgt_var), \"norm\": self.def_norm_img},\n",
    "                'Predicted Target': {\"img\": get_np(viz_pred_tgt_var), \"norm\": self.def_norm_img},\n",
    "                'Diff': {\"img\": get_np(viz_diff_var), \"norm\": self.def_norm_img},\n",
    "                'Masked Diff': {\"img\": get_np(viz_masked_diff_var),\n",
    "                                \"norm\": self.def_norm_img},\n",
    "                'MSE Mask': {\"img\": get_np(viz_mse_mask_var)},\n",
    "                'Masked Norm Diff': {\"img\": get_np(viz_masked_nrom_diff_var), \"norm\": self.def_norm_img},\n",
    "                'Smoothness': {\"img\": get_np(viz_smoothness_penalty_var), \"norm\": self.def_norm_img},\n",
    "                'Rigidity': {\"img\": get_np(viz_rigidity_penalty_var), \"norm\": self.def_norm_img},\n",
    "                'Smoothness Mask': {\"img\": get_np(viz_smoothness_mask_var)},\n",
    "                'Masked Smoothness': {\"img\": get_np(viz_smoothness_mask_var * viz_smoothness_penalty_var), \n",
    "                                      \"norm\": self.def_norm_img},\n",
    "                'Masked Rigidity': {\"img\": get_np(viz_smoothness_mask_var * viz_rigidity_penalty_var), \n",
    "                                      \"norm\": self.def_norm_img},\n",
    "            }\n",
    "\n",
    "            self.vect_dict = {\n",
    "                'Predicted Residual': get_np(viz_pred_res_var),\n",
    "                'Source Residual': get_np(src_res_var),\n",
    "                'Inverted Residual': get_np(viz_inv_res),\n",
    "                'Combined': get_np(combined_identity_var)\n",
    "            }\n",
    "            \n",
    "            self.hist_dict = {\n",
    "                'Residual Histogram': get_np(viz_pred_res_var),\n",
    "            }\n",
    "            \n",
    "            if self.sup:\n",
    "                self.vect_dict['True Residual'] = get_np(viz_true_res_var),\n",
    "                self.vect_dict['Residual Error'] =  get_np(viz_true_res_var - viz_pred_res_var)\n",
    "    \n",
    "    def clean_up(self):\n",
    "        self.img_dict = {}\n",
    "        self.vect_dict = {}\n",
    "       \n",
    "    def loadimg(self, val, sup, section_count, img_id, x_section, y_section, choice, state_file):\n",
    "        self.update_state(img_id, sup, val, state_file)\n",
    "        \n",
    "        if choice in self.img_dict:\n",
    "            normalize = ('norm' in self.img_dict[choice]) and (self.img_dict[choice]['norm'])\n",
    "            is_mask = ('Mask ' in choice) or (' Mask' in choice)\n",
    "            is_seg = ('segment' in choice.lower())\n",
    "            img = copy.copy(prepare_for_show(self.img_dict[choice]['img']))\n",
    "            \n",
    "            x_section_size = img.shape[0] // section_count\n",
    "            y_section_size = img.shape[1] // section_count\n",
    "            \n",
    "            x_coords = (x_section_size * x_section, x_section_size * (x_section + 1))\n",
    "            y_coords = (y_section_size * y_section, y_section_size * (y_section + 1))\n",
    "\n",
    "            if choice in ['Diff',  'Masked Diff']:\n",
    "                print ('MSE: {}'.format(np.mean(np.abs(img[x_coords[0]:x_coords[1], y_coords[0]:y_coords[1]]))))\n",
    "            display_image(img, mask=is_mask, segmentation=is_seg, normalize=normalize, x_coords=x_coords, y_coords=y_coords)\n",
    "            \n",
    "        elif choice in self.vect_dict:\n",
    "            vecs = prepare_for_show(self.vect_dict[choice])\n",
    "\n",
    "            x_section_size = vecs.shape[1] // section_count\n",
    "            y_section_size = vecs.shape[2] // section_count\n",
    "            \n",
    "            x_coords = (x_section_size * x_section, x_section_size * (x_section + 1))\n",
    "            y_coords = (y_section_size * y_section, y_section_size * (y_section + 1))\n",
    "            \n",
    "            \n",
    "            visualize_residuals(vecs, x_coords=x_coords, y_coords=y_coords)\n",
    "\n",
    "        elif choice in self.hist_dict:\n",
    "            img = self.hist_dict[choice]\n",
    "            x_section_size = img.shape[0] // section_count\n",
    "            y_section_size = img.shape[1] // section_count\n",
    "            \n",
    "            x_coords = (x_section_size * x_section, x_section_size * (x_section + 1))\n",
    "            y_coords = (y_section_size * y_section, y_section_size * (y_section + 1))\n",
    "            visualize_histogram(img, x_coords=x_coords, y_coords=y_coords)\n",
    "       \n",
    "    def visualize(self, section_count=1, state_file=None, default_slice=9, default_x=0, default_y=0):\n",
    "        \n",
    "        self.id_selector = widgets.IntText(\n",
    "            value=default_slice,\n",
    "            description='Sample ID:',\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "        self.val_selector = widgets.Checkbox(\n",
    "            value=False,\n",
    "            description='Take from validation set',\n",
    "            disabled=False\n",
    "        )\n",
    "        self.sup_selector = widgets.Checkbox(\n",
    "            value=self.def_sup,\n",
    "            description='Take from supervised dataset',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        self.section_count_selector = widgets.IntText(\n",
    "            value=section_count,\n",
    "            description='Section Count:',\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "        self.x_section_selector = widgets.IntText(\n",
    "            value=default_x,\n",
    "            description='X section:',\n",
    "            disabled=False\n",
    "        )\n",
    "        self.y_section_selector = widgets.IntText(\n",
    "            value=default_y,\n",
    "            description='Y section:',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        buttons = ['Source', 'Warped Source', 'Target', 'Predicted Target', \n",
    "                   'Source Residual', 'Predicted Residual', 'Inverted Residual', \n",
    "                   'Combined',  'Diff', 'MSE Mask', 'Masked Diff', 'Residual Histogram',\n",
    "                   'Smoothness Mask', 'Smoothness', 'Rigidity', 'Masked Smoothness', 'Masked Rigidity']\n",
    "\n",
    "        # for supervised\n",
    "        #buttons += ['True Residual', 'Error histogram', 'Vector histogram', 'Residual Error'],\n",
    "        self.button_choice_1 = widgets.ToggleButtons(\n",
    "            options=buttons,\n",
    "            description='Choice:',\n",
    "            disabled=False,\n",
    "            button_style='',\n",
    "        #     icons=['check'] * 3\n",
    "        )\n",
    "        interact(self.loadimg, img_id=self.id_selector, val=self.val_selector, sup=self.sup_selector, \n",
    "                 section_count=self.section_count_selector, x_section=self.x_section_selector, y_section=self.y_section_selector, \n",
    "                 choice=self.button_choice_1, state_file=fixed(state_file))\n",
    "\n",
    "\n",
    "\n",
    "def get_datasets():\n",
    "    dataset_mip = 7\n",
    "    stage = 0\n",
    "    checkpoint_name = 'mse_final'\n",
    "    \n",
    "    #big_data = dataset.MultimipDataset(\"/usr/people/popovych/metro_datasets/large_test_x1\", field_tag=checkpoint_name)\n",
    "    big_data = dataset.MultimipDataset(\"/usr/people/popovych/metro_datasets/fly_full_x4_bigtest\", field_tag=checkpoint_name)\n",
    "    train_dataset = big_data.get_train_dset(mip=dataset_mip, stage=stage, crop_mode='middle', cropped_size=2048)\n",
    "    return dataset_mip, train_dataset\n",
    "    \n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "\n",
    "MAX_SEG_PER_CHUNK = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/people/popovych/metro_models/pure_emb_x0/0_mip7in_purity/model/model_spec.json\n",
      "average_pool.json\n",
      "embedder_fms1to1.json\n",
      "block_3convs_3x3_fms1to32to1.json\n",
      "average_pool.json\n",
      "block_3convs_3x3_fms1to32to1.json\n",
      "average_pool.json\n",
      "embedder_fms2to3.json\n",
      "block_3convs_3x3_fms2to32to3.json\n",
      "average_pool.json\n",
      "block_3convs_3x3_fms3to32to3.json\n",
      "average_pool.json\n",
      "embedder_fms4to3.json\n",
      "block_3convs_3x3_fms4to32to3.json\n",
      "average_pool.json\n",
      "block_3convs_3x3_fms3to32to3.json\n",
      "average_pool.json\n",
      "embedder_fms4to3.json\n",
      "block_3convs_3x3_fms4to32to3.json\n",
      "average_pool.json\n",
      "block_3convs_3x3_fms3to32to3.json\n",
      "average_pool.json\n",
      "embedder_fms4to3.json\n",
      "block_3convs_3x3_fms4to32to3.json\n",
      "average_pool.json\n",
      "block_3convs_3x3_fms3to32to3.json\n",
      "identity.json\n",
      "identity.json\n",
      "identity.json\n",
      "identity.json\n",
      "identity.json\n",
      "identity.json\n",
      "identity.json\n",
      "upsample_residuals.json\n",
      "identity.json\n",
      "Adding 'x10240_y0_z200' dataset.\n",
      "Loading file '/usr/people/popovych/metro_datasets/fly_full_x4_bigtest/x10240_y0_z200_MIP7.h5...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8192d4e6ebe5419e9c235f2a7de5c805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=False, description='Take from validation set'), Checkbox(value=True, desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checkpiont = \"spynet_x0\"\n",
    "#checkpoint_folder = \"/usr/people/popovych/metro_models/spynet_m4m6m9/0_mip4in_mip4569module/model\" #\"/usr/people/popovych/aligner/experiments/{}\".format(pyramid_name)\n",
    "\n",
    "#checkpiont = \"rigid_net\"\n",
    "checkpoint = \"starge3_base\"\n",
    "checkpoint = \"stage5_revive_x0\"\n",
    "#checkpoint_folder = \"/usr/people/popovych/metro_models/pyramid_m4m6m9/0_mip7in_mip9module/model\" #\"/usr/people/popovych/aligner/experiments/{}\".format(pyramid_name)\n",
    "\n",
    "checkpoint_folder = \"/usr/people/popovych/metro_models/pure_emb_x0/0_mip7in_purity/model\" #\"/usr/people/popovych/aligner/experiments/{}\".format(pyramid_name)\n",
    "\n",
    "#checkpoint_folder = \"/usr/people/popovych/metro_models/pyramid_m4m6m9/2_mip4in_mip4module/model\" #\"/usr/people/popovych/aligner/experiments/{}\".format(pyramid_name)\n",
    "#checkpoint_folder = \"/usr/people/popovych/metro_models/pyramid_m5m9/1_mip4in_mip5module/model\" #\"/usr/people/popovych/aligner/experiments/{}\".format(pyramid_name)\n",
    "\n",
    "test_pyramid = aligner.Aligner(checkpoint_folder, checkpoint_name=checkpoint, train=False, \n",
    "                               finetune_lr=3e-1, finetune_sm=200e0, finetune_iter=200, finetune=False)\n",
    "viz1 = PyramidVisualizer(test_pyramid)\n",
    "run_mip = 0\n",
    "\n",
    "viz1.def_norm_img = True\n",
    "viz1.set_model(test_pyramid)\n",
    "viz1.visualize(section_count=1, default_slice=3228, default_x=0, default_y=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import modelhouse\n",
    "import metroem\n",
    "\n",
    "from metroem import finetuner\n",
    "from metroem import masks\n",
    "importlib.reload(finetuner)\n",
    "importlib.reload(masks)\n",
    "from metroem.finetuner import optimize_pre_post_ups\n",
    "\n",
    "def opt(src, tgt, pred_res_start, src_defects=None, tgt_defects=None, lr=18e-1, sm=2e1, num_iter=100):\n",
    "    mse_keys_to_apply = {\n",
    "\n",
    "    }\n",
    "    sm_keys_to_apply = {  \n",
    "\n",
    "          \n",
    "    }\n",
    "    \n",
    "    src_small_defects = None\n",
    "    src_large_defects = None\n",
    "    \n",
    "        \n",
    "    if src_small_defects is not None:\n",
    "        src_small_defects = src_small_defects.squeeze(0)\n",
    "    else:\n",
    "        src_small_defects = torch.zeros_like(src)\n",
    "        \n",
    "    if src_large_defects is not None:\n",
    "        src_large_defects = src_large_defects.squeeze(0)\n",
    "    else:\n",
    "        src_large_defects = torch.zeros((src.shape[-1], src.shape[-1]))\n",
    "    \n",
    "    pred_res_opt = optimize_pre_post_ups(src, tgt, pred_res_start,\n",
    "            src_defects=torch.zeros_like(src_defects),\n",
    "            tgt_defects=torch.zeros_like(tgt_defects),\n",
    "            crop=1, num_iter=num_iter,\n",
    "            opt_res_coarsness=0,\n",
    "            sm_keys_to_apply=sm_keys_to_apply,\n",
    "            mse_keys_to_apply=mse_keys_to_apply,\n",
    "            normalize=True,\n",
    "            nailed_check_period=100,\n",
    "            mask_around_nailed=False,\n",
    "            verbose=True,\n",
    "            sm=sm, lr=lr)\n",
    "    \n",
    "    return pred_res_opt\n",
    "\n",
    "class OptiPrecoarse(torch.nn.Module):\n",
    "    def __init__(self, embedder_path=None, \n",
    "                 embedder_params={\n",
    "                    \"checkpoint_name\": \"stage3_x0\",\n",
    "                    \"finetune\": False\n",
    "                },\n",
    "                 device='cuda',\n",
    "                 level=-1,\n",
    "                 sm=2e1,\n",
    "                 mask_value=-1,\n",
    "                 num_iter=1000,\n",
    "                 lr=18e-1\n",
    "                ):\n",
    "        super().__init__()\n",
    "        if embedder_path is not None:\n",
    "            self.embedder = modelhouse.loading.uncached_load_model_str(embedder_path, params=json.dumps(embedder_params)).to(device)\n",
    "        else:\n",
    "            self.embedder = None\n",
    "        self.device = device\n",
    "        self.level = level\n",
    "        self.sm = sm\n",
    "        self.mask_value = mask_value\n",
    "        self.lr = lr\n",
    "        self.num_iter = num_iter\n",
    "        \n",
    "    def forward(self, src_img, tgt_img, src_agg_field=None):\n",
    "        #self.embedder(src_img=src_img, tgt_img=tgt_img)\n",
    "        if self.embedder is not None:\n",
    "            src_emb = self.embedder.aligner.get_embeddings(src_img, level=self.level, preserve_zeros=True)\n",
    "            tgt_emb = self.embedder.aligner.get_embeddings(tgt_img, level=self.level, preserve_zeros=True)\n",
    "        else:\n",
    "            src_emb = src_img\n",
    "            tgt_emb = tgt_img\n",
    "        \n",
    "        padded = False\n",
    "        if src_emb.shape[-1] < 256:\n",
    "            padded = True\n",
    "            src_emb = torch.nn.functional.pad(src_emb, [8, 8, 8, 8])\n",
    "            tgt_emb = torch.nn.functional.pad(tgt_emb, [8, 8, 8, 8])\n",
    "            if src_agg_field is not None:\n",
    "                src_agg_field = torch.nn.functional.pad(src_agg_field, [8, 8, 8, 8])\n",
    "        src_mask = src_emb[0] == 0\n",
    "        tgt_mask = tgt_emb[0] == 0\n",
    "        src_emb[:, src_mask] = self.mask_value\n",
    "        tgt_emb[:, tgt_mask] = self.mask_value\n",
    "        \n",
    "        if src_agg_field is None:\n",
    "            res_start = torch.zeros([1, 2, tgt_emb.shape[-1], src_emb.shape[-1]]).to(self.device)\n",
    "        else:\n",
    "            res_start = src_agg_field\n",
    "            res_start = res_start.from_pixels()\n",
    "            while res_start.shape[-1] < src_emb.shape[-1]:\n",
    "                res_start = res_start.up()\n",
    "            res_start = res_start.pixels()\n",
    "            \n",
    "        pred_res_opt = 0\n",
    "        pred_res_opt = opt(\n",
    "            src_emb.unsqueeze(0), \n",
    "            tgt_emb.unsqueeze(0), \n",
    "            res_start, \n",
    "            src_defects=torch.zeros_like(src_mask, device=self.device), \n",
    "            tgt_defects=torch.zeros_like(src_mask, device=self.device), \n",
    "            lr=self.lr,\n",
    "            sm=self.sm,\n",
    "            num_iter=self.num_iter\n",
    "        )\n",
    "        \n",
    "        if padded:\n",
    "            padded = True\n",
    "            src_emb = torch.nn.functional.pad(src_emb, [-8, -8, -8, -8])\n",
    "            tgt_emb = torch.nn.functional.pad(tgt_emb, [-8, -8, -8, -8])\n",
    "            pred_res_opt = torch.nn.functional.pad(pred_res_opt, [-8, -8, -8, -8]).field()\n",
    "        \n",
    "        return src_emb, tgt_emb, pred_res_opt, src_mask\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/people/popovych/.modelhouse/tmp_files/tmpwgb8bzx3/model/model_spec.json\n",
      "average_pool.json\n",
      "embedder_fms1to1.json\n",
      "block_3convs_3x3_fms1to32to1.json\n",
      "average_pool.json\n",
      "block_3convs_3x3_fms1to32to1.json\n",
      "average_pool.json\n",
      "embedder_fms2to3.json\n",
      "block_3convs_3x3_fms2to32to3.json\n",
      "average_pool.json\n",
      "block_3convs_3x3_fms3to32to3.json\n",
      "average_pool.json\n",
      "embedder_fms4to3.json\n",
      "block_3convs_3x3_fms4to32to3.json\n",
      "average_pool.json\n",
      "block_3convs_3x3_fms3to32to3.json\n",
      "average_pool.json\n",
      "embedder_fms4to3.json\n",
      "block_3convs_3x3_fms4to32to3.json\n",
      "average_pool.json\n",
      "block_3convs_3x3_fms3to32to3.json\n",
      "average_pool.json\n",
      "embedder_fms4to3.json\n",
      "block_3convs_3x3_fms4to32to3.json\n",
      "average_pool.json\n",
      "block_3convs_3x3_fms3to32to3.json\n",
      "identity.json\n",
      "identity.json\n",
      "identity.json\n",
      "identity.json\n",
      "identity.json\n",
      "identity.json\n",
      "identity.json\n",
      "upsample_residuals.json\n",
      "identity.json\n",
      "SAMPLE 3227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/people/popovych/env/corgie_merge/lib/python3.7/site-packages/ipykernel_launcher.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/people/popovych/env/corgie_merge/lib/python3.7/site-packages/ipykernel_launcher.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04aa62e2fdc4031aac4dd33da933086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13273741 0.13273741 0.0\n",
      "New best: 38, No impr: 0, NaN: 0, Iter: 99\n",
      "0.1283486 0.12751704 0.00083155645\n",
      "42.159483671188354\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "stage = 5\n",
    "checkpoint_name = \"stage5_x0_lowmin_win4_uni\"\n",
    "checkpoint_name = f\"stage{stage}_revive_x10\"\n",
    "opt_pc_m10 = OptiPrecoarse(\n",
    "    mask_value=0,#,-src_emb.max()*5, \n",
    "    embedder_path='/usr/people/popovych/metro_models/pure_emb_x0/0_mip7in_purity',\n",
    "    embedder_params={\n",
    "        #\"checkpoint_name\":  f\"stage{stage}_x0_lowmin_win4\",\n",
    "        \"checkpoint_name\":  checkpoint_name,\n",
    "        \"finetune\": False\n",
    "    },\n",
    "    level=stage,\n",
    "    sm=23e-2,\n",
    "    lr=3e-1,\n",
    "    num_iter=100,\n",
    ")\n",
    "\n",
    "n = random.choice(range(0, 4500))\n",
    "n = 3227\n",
    "print (f\"SAMPLE {n}\")\n",
    "sample = viz1.dataset[n]\n",
    "\n",
    "src = torch.tensor(sample['src'], device='cuda').unsqueeze(0)\n",
    "tgt = torch.tensor(sample['tgt'], device='cuda').unsqueeze(0)\n",
    "\n",
    "inits = []\n",
    "reses = []\n",
    "good_pxs = []\n",
    "best_result = 1e10\n",
    "res = None\n",
    "for _ in tqdm(list(range(1))):\n",
    "    init_field = None\n",
    "    src_emb, tgt_emb, res, src_mask = opt_pc_m10.forward(src_img=src, tgt_img=tgt, src_agg_field=init_field)\n",
    "    curr_result = (tgt_emb[0] - res.from_pixels()(src_emb[0])).abs().sum()\n",
    "\n",
    "    pred_tgt = res.from_pixels()(src_emb[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9987, device='cuda:0', grad_fn=<MaxBackward1>),\n",
       " tensor(0.1794, device='cuda:0'))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.abs().max(), src_emb.abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c978e6ee8df94cee8dabb60eb95a6e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Image:', options=(0, 1, 2, 3, 4, 5), value=0), IntText(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v = [ src_emb[0],  tgt_emb[0], pred_tgt, res.from_pixels(), src, tgt]\n",
    "simple_visualizer().visualize(v, section_count=1, x_section=0, y_section=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0146, device='cuda:0'),\n",
       " tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(src_emb[0]-tgt_emb[0]).abs().mean(), (pred_tgt - tgt_emb[0]).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491e6fd9b6074264a281ffc9224856df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Image:', options=(0, 1, 2), value=0), IntText(value=1, descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_ups = res.clone().from_pixels()\n",
    "\n",
    "while res_ups.shape[-1] < src.shape[-1]:\n",
    "    res_ups = res_ups.up()\n",
    "v = [ src,  tgt, res_ups(src)]\n",
    "simple_visualizer().visualize(v, section_count=1, x_section=0, y_section=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corige_merge",
   "language": "python",
   "name": "corgie_merge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
